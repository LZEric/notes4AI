## Python常用包
科学计算：Sklearn, Numpy, Pandas
人工智能：Tensorflow, PyTorch
网络爬虫：Scrapy, Request, BeautifulSoap
运筹优化：ortools, pulp
保存模型：pickle（方便把任何python变量进行保存）
数据网址：kaggle.com

loss =》误差

f(x) = w^1x^1+w^2x^2+w^3x^3+b = w^t*x + b

b为残差

训练数据和测试数据的MAE相差过大，大概率为过拟合

CatBoost：category boost，偏向于类别，不太容易过拟合
XGBoost：
## 模型选择
回归问题：连续的数据，无限的
分类问题：离散的数据，有限的
线性回归：对应回归问题
逻辑回归：对应分类问题，线性模型，规律简单，仅看单个特征的影响力
决策树：分段，非线性模型，规律相对复杂（树的深度为3～7之间，便于人阅读，并保证准确度，精度更高则8～10，越深越容易过拟合）

越难（需要考虑的维度多）的问题，需要的样本量越多
影响很小的维度尽量不拿去做训练

奥卡姆剃刀定律：越简单越有效

• 分类算法：C4.5，朴素贝叶斯（Naive Bayes），SVM，KNN，Adaboost，CART

• 聚类算法：K-Means，EM（将大量的数据先进行分类，对数据进行降维，降低难度；聚类是机器自主进行分类，分类：人先定好了规则然后进行划分）

• 关联分析：Apriori（如果一个节点出现，另一个节点大概率也会出现）

• 连接分析：PageRank（影响力分析，找到影响力最大的节点，简化数据）
## 模型评估

要留10%，20%的数据作为测试集

超参数调整=》人工可以调节的参数

AUC：准确度（准确率和召回率）
EPOCH：一次完整数据的训练，一共1w个房价的数据集，将这些训练完了，就是一次epoch
EDA（探索性数据分析）：一般在建模之前执行，做数据的可视化预览，大体看看数据长什么样
IV：inforamtion value，专门衡量特征重要性的，大雨0.02

指令：帮我进行EDA（探索性数据分析）